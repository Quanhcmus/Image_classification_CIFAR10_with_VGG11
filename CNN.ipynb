{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Quanhcmus/Image_classification_CIFAR10_with_VGG11/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4Klj7uvv339",
        "outputId": "3c4ec3f7-7fcb-4ba0-e25d-a35426af4dd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n",
            "x_train shape: (37500, 32, 32, 3)\n",
            "37500 train samples\n",
            "12500 valid samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import Conv2D, Flatten,AveragePooling2D\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "num_class=10\n",
        "batch_size=32\n",
        "epoch=50\n",
        "data_augmentation = True\n",
        "\n",
        "(X,y),(X_test,y_test)=cifar10.load_data()\n",
        "X_train,X_valid,y_train,y_valid=train_test_split(X,y,test_size=0.25,random_state=42)\n",
        "print('x_train shape:', X_train.shape)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_valid.shape[0], 'valid samples')\n",
        "print(X_test.shape[0], 'test samples')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mVnmWvyNv33_"
      },
      "outputs": [],
      "source": [
        "# Convert class vectors to binary class matrices.\n",
        "y_train=keras.utils.to_categorical(y_train)\n",
        "y_test=keras.utils.to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nsUu069fv33_"
      },
      "outputs": [],
      "source": [
        "# tất cả các pixel của ảnh đều nằm trong khoảnh [0;255] nên chia cho 255 để tất cả đều nằm trong khoảng [0;1]\n",
        "X_train=X_train.astype('float32')\n",
        "X_test=X_test.astype('float32')\n",
        "X_train/=255\n",
        "X_test/=255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NW5O5vCav33_",
        "outputId": "cf9a42a3-c74c-4974-afc6-91493e06f997"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 6)         456       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 28, 28, 6)         0         \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 14, 14, 6)        0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 10, 10, 16)        2416      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 10, 10, 16)        0         \n",
            "                                                                 \n",
            " average_pooling2d_1 (Averag  (None, 5, 5, 16)         0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 400)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 120)               48120     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 120)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 120)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 84)                0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 84)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Letnet5\n",
        "\n",
        "model= Sequential()\n",
        "\n",
        "model.add(Conv2D(6,(5,5),input_shape=X_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(AveragePooling2D())\n",
        "\n",
        "model.add(Conv2D(16,(5,5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(AveragePooling2D())\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(120))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense(84))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.Adam(lr=0.0001)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xMFcUXUkv33_"
      },
      "outputs": [],
      "source": [
        "tbCallBack = keras.callbacks.TensorBoard(log_dir='./Graph2', histogram_freq=0, write_graph=True, write_images=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPt1IWThv33_",
        "outputId": "0801b698-57c4-422d-d5e9-d9fd76fbfac8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-fafaa43913b4>:42: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(datagen.flow(X_train, y_train,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1171/1171 [==============================] - 37s 24ms/step - loss: 2.1817 - accuracy: 0.1834 - val_loss: 1.9871 - val_accuracy: 0.2796\n",
            "Epoch 2/50\n",
            "1171/1171 [==============================] - 27s 23ms/step - loss: 2.0116 - accuracy: 0.2558 - val_loss: 1.8424 - val_accuracy: 0.3395\n",
            "Epoch 3/50\n",
            "1171/1171 [==============================] - 28s 24ms/step - loss: 1.9131 - accuracy: 0.2943 - val_loss: 1.7124 - val_accuracy: 0.3875\n",
            "Epoch 4/50\n",
            "1171/1171 [==============================] - 27s 23ms/step - loss: 1.8391 - accuracy: 0.3201 - val_loss: 1.6586 - val_accuracy: 0.4048\n",
            "Epoch 5/50\n",
            "1171/1171 [==============================] - 28s 24ms/step - loss: 1.7820 - accuracy: 0.3439 - val_loss: 1.5952 - val_accuracy: 0.4255\n",
            "Epoch 6/50\n",
            "1171/1171 [==============================] - 30s 26ms/step - loss: 1.7529 - accuracy: 0.3522 - val_loss: 1.5616 - val_accuracy: 0.4367\n",
            "Epoch 7/50\n",
            "1171/1171 [==============================] - 28s 24ms/step - loss: 1.7271 - accuracy: 0.3632 - val_loss: 1.5556 - val_accuracy: 0.4424\n",
            "Epoch 8/50\n",
            "1171/1171 [==============================] - 28s 24ms/step - loss: 1.7112 - accuracy: 0.3706 - val_loss: 1.5474 - val_accuracy: 0.4409\n",
            "Epoch 9/50\n",
            "1171/1171 [==============================] - 27s 23ms/step - loss: 1.6891 - accuracy: 0.3777 - val_loss: 1.4973 - val_accuracy: 0.4658\n",
            "Epoch 10/50\n",
            "1171/1171 [==============================] - 27s 23ms/step - loss: 1.6769 - accuracy: 0.3855 - val_loss: 1.5151 - val_accuracy: 0.4532\n",
            "Epoch 11/50\n",
            "1171/1171 [==============================] - 28s 24ms/step - loss: 1.6623 - accuracy: 0.3896 - val_loss: 1.5232 - val_accuracy: 0.4543\n",
            "Epoch 12/50\n",
            "1171/1171 [==============================] - 27s 23ms/step - loss: 1.6463 - accuracy: 0.3935 - val_loss: 1.5188 - val_accuracy: 0.4533\n",
            "Epoch 13/50\n",
            "1171/1171 [==============================] - 27s 23ms/step - loss: 1.6363 - accuracy: 0.3993 - val_loss: 1.4387 - val_accuracy: 0.4812\n",
            "Epoch 14/50\n",
            "1171/1171 [==============================] - 27s 23ms/step - loss: 1.6272 - accuracy: 0.4035 - val_loss: 1.4527 - val_accuracy: 0.4730\n",
            "Epoch 15/50\n",
            "1171/1171 [==============================] - 27s 23ms/step - loss: 1.6203 - accuracy: 0.4073 - val_loss: 1.4433 - val_accuracy: 0.4749\n",
            "Epoch 16/50\n",
            "1171/1171 [==============================] - 27s 23ms/step - loss: 1.6050 - accuracy: 0.4142 - val_loss: 1.4022 - val_accuracy: 0.4930\n",
            "Epoch 17/50\n",
            "1171/1171 [==============================] - 27s 23ms/step - loss: 1.5968 - accuracy: 0.4171 - val_loss: 1.4007 - val_accuracy: 0.4944\n",
            "Epoch 18/50\n",
            "1171/1171 [==============================] - 27s 23ms/step - loss: 1.5935 - accuracy: 0.4165 - val_loss: 1.4169 - val_accuracy: 0.4901\n",
            "Epoch 19/50\n",
            "1171/1171 [==============================] - 27s 23ms/step - loss: 1.5810 - accuracy: 0.4231 - val_loss: 1.4080 - val_accuracy: 0.4911\n",
            "Epoch 20/50\n",
            "1171/1171 [==============================] - 27s 23ms/step - loss: 1.5726 - accuracy: 0.4283 - val_loss: 1.4012 - val_accuracy: 0.4898\n",
            "1171/1171 [==============================] - 27s 23ms/step - loss: 1.5647 - accuracy: 0.4325 - val_loss: 1.3605 - val_accuracy: 0.5143\n",
            "Epoch 22/50\n",
            "1171/1171 [==============================] - 27s 23ms/step - loss: 1.5568 - accuracy: 0.4381 - val_loss: 1.3719 - val_accuracy: 0.5070\n",
            "Epoch 23/50\n",
            "1171/1171 [==============================] - 28s 24ms/step - loss: 1.5519 - accuracy: 0.4358 - val_loss: 1.3672 - val_accuracy: 0.5114\n",
            "Epoch 24/50\n",
            "1171/1171 [==============================] - 28s 24ms/step - loss: 1.5380 - accuracy: 0.4411 - val_loss: 1.3753 - val_accuracy: 0.5035\n",
            "Epoch 25/50\n",
            "1171/1171 [==============================] - 28s 24ms/step - loss: 1.5384 - accuracy: 0.4418 - val_loss: 1.3575 - val_accuracy: 0.5083\n",
            "Epoch 26/50\n",
            "1171/1171 [==============================] - 27s 23ms/step - loss: 1.5325 - accuracy: 0.4442 - val_loss: 1.3677 - val_accuracy: 0.5051\n",
            "Epoch 27/50\n",
            "1171/1171 [==============================] - 27s 23ms/step - loss: 1.5252 - accuracy: 0.4467 - val_loss: 1.3531 - val_accuracy: 0.5122\n",
            "Epoch 28/50\n",
            "1171/1171 [==============================] - 27s 23ms/step - loss: 1.5108 - accuracy: 0.4522 - val_loss: 1.3589 - val_accuracy: 0.5131\n",
            "Epoch 29/50\n",
            "1171/1171 [==============================] - 28s 24ms/step - loss: 1.5101 - accuracy: 0.4517 - val_loss: 1.3010 - val_accuracy: 0.5317\n",
            "Epoch 30/50\n",
            "1171/1171 [==============================] - 28s 24ms/step - loss: 1.5073 - accuracy: 0.4545 - val_loss: 1.3500 - val_accuracy: 0.5168\n",
            "Epoch 31/50\n",
            "1171/1171 [==============================] - 28s 24ms/step - loss: 1.4963 - accuracy: 0.4558 - val_loss: 1.3332 - val_accuracy: 0.5119\n",
            "Epoch 32/50\n",
            "1171/1171 [==============================] - 27s 23ms/step - loss: 1.4929 - accuracy: 0.4610 - val_loss: 1.3609 - val_accuracy: 0.5034\n",
            "Epoch 33/50\n",
            "1171/1171 [==============================] - 28s 24ms/step - loss: 1.4870 - accuracy: 0.4624 - val_loss: 1.2795 - val_accuracy: 0.5386\n",
            "Epoch 34/50\n",
            "1171/1171 [==============================] - 30s 26ms/step - loss: 1.4932 - accuracy: 0.4607 - val_loss: 1.3629 - val_accuracy: 0.5057\n",
            "Epoch 35/50\n",
            "1171/1171 [==============================] - 28s 24ms/step - loss: 1.4786 - accuracy: 0.4670 - val_loss: 1.3128 - val_accuracy: 0.5307\n",
            "Epoch 36/50\n",
            "1171/1171 [==============================] - 27s 23ms/step - loss: 1.4724 - accuracy: 0.4696 - val_loss: 1.3094 - val_accuracy: 0.5284\n",
            "Epoch 37/50\n",
            "1171/1171 [==============================] - 29s 25ms/step - loss: 1.4700 - accuracy: 0.4684 - val_loss: 1.3037 - val_accuracy: 0.5281\n",
            "Epoch 38/50\n",
            "1171/1171 [==============================] - 28s 24ms/step - loss: 1.4698 - accuracy: 0.4696 - val_loss: 1.2951 - val_accuracy: 0.5309\n",
            "Epoch 39/50\n",
            "1171/1171 [==============================] - 28s 24ms/step - loss: 1.4599 - accuracy: 0.4732 - val_loss: 1.3248 - val_accuracy: 0.5220\n",
            "Epoch 40/50\n",
            "1171/1171 [==============================] - 28s 24ms/step - loss: 1.4604 - accuracy: 0.4749 - val_loss: 1.2685 - val_accuracy: 0.5386\n",
            "Epoch 41/50\n",
            "1171/1171 [==============================] - 28s 24ms/step - loss: 1.4591 - accuracy: 0.4721 - val_loss: 1.3022 - val_accuracy: 0.5318\n",
            "Epoch 42/50\n",
            "1171/1171 [==============================] - 27s 23ms/step - loss: 1.4516 - accuracy: 0.4762 - val_loss: 1.2890 - val_accuracy: 0.5345\n",
            "Epoch 43/50\n",
            "1171/1171 [==============================] - 28s 24ms/step - loss: 1.4525 - accuracy: 0.4766 - val_loss: 1.2885 - val_accuracy: 0.5415\n",
            "Epoch 44/50\n",
            "1171/1171 [==============================] - 28s 24ms/step - loss: 1.4491 - accuracy: 0.4775 - val_loss: 1.3133 - val_accuracy: 0.5292\n",
            "Epoch 45/50\n",
            "1171/1171 [==============================] - 28s 24ms/step - loss: 1.4428 - accuracy: 0.4796 - val_loss: 1.2684 - val_accuracy: 0.5424\n",
            "Epoch 46/50\n",
            "1171/1171 [==============================] - 31s 26ms/step - loss: 1.4323 - accuracy: 0.4865 - val_loss: 1.2569 - val_accuracy: 0.5436\n",
            "Epoch 47/50\n",
            "1171/1171 [==============================] - 29s 25ms/step - loss: 1.4347 - accuracy: 0.4831 - val_loss: 1.2690 - val_accuracy: 0.5378\n",
            "Epoch 48/50\n",
            "1171/1171 [==============================] - 27s 23ms/step - loss: 1.4332 - accuracy: 0.4819 - val_loss: 1.2406 - val_accuracy: 0.5486\n",
            "Epoch 49/50\n",
            "1171/1171 [==============================] - 28s 24ms/step - loss: 1.4245 - accuracy: 0.4873 - val_loss: 1.2539 - val_accuracy: 0.5514\n",
            "Epoch 50/50\n",
            "1171/1171 [==============================] - 27s 23ms/step - loss: 1.4232 - accuracy: 0.4882 - val_loss: 1.2638 - val_accuracy: 0.5475\n"
          ]
        }
      ],
      "source": [
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(X_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epoch,\n",
        "              validation_data=(X_test, y_test),\n",
        "              shuffle=True, callbacks=[tbCallBack])\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    '''\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "    '''\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(X_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model.fit_generator(datagen.flow(X_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        steps_per_epoch=X_train.shape[0] // batch_size,\n",
        "                        epochs=epoch,\n",
        "                        validation_data=(X_test, y_test), callbacks=[tbCallBack])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores=model.evaluate(X_test,y_test,verbose=1)\n",
        "print(\"Test Loss\",scores[0])\n",
        "print(\"Test Accuracy\",scores[1])"
      ],
      "metadata": {
        "id": "FUBxhLYZ8XgP",
        "outputId": "65a4f2ec-6b08-45b1-cf8f-081499058971",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 1.2638 - accuracy: 0.5475\n",
            "Test Loss 1.2637794017791748\n",
            "Test Accuracy 0.5475000143051147\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}