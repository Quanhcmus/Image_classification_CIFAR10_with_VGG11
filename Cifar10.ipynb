{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Quanhcmus/Image_classification_CIFAR10_with_VGG11/blob/main/Cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2cBOVh4OuGg",
        "outputId": "84ac7261-65eb-46e4-874a-cc976fa297a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "num_class=10\n",
        "batch_size=32\n",
        "epoch=50\n",
        "data_augmentation = True\n",
        "\n",
        "(X,y),(X_test,y_test)=cifar10.load_data()\n",
        "X_train,X_valid,y_train,y_valid=train_test_split(X,y,test_size=0.25,random_state=42)\n",
        "print('x_train shape:', X_train.shape)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_valid.shape[0], 'valid samples')\n",
        "print(X_test.shape[0], 'test samples')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KQWSq-iOuGh"
      },
      "outputs": [],
      "source": [
        "# Convert class vectors to binary class matrices.\n",
        "y_train=keras.utils.to_categorical(y_train)\n",
        "y_test=keras.utils.to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vbOhrT1OuGh"
      },
      "outputs": [],
      "source": [
        "# tất cả các pixel của ảnh đều nằm trong khoảnh [0;255] nên chia cho 255 để tất cả đều nằm trong khoảng [0;1]\n",
        "X_train=X_train.astype('float32')\n",
        "X_test=X_test.astype('float32')\n",
        "X_train/=255\n",
        "X_test/=255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAYUaQEMOuGh",
        "outputId": "5e8ce819-1b70-453a-bf4b-8e0dd06982d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 2, 2, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " global_max_pooling2d (Globa  (None, 512)              0         \n",
            " lMaxPooling2D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              2101248   \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                40970     \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,144,010\n",
            "Trainable params: 28,144,010\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# VGG model\n",
        "model=Sequential()\n",
        "\n",
        "# block 1\n",
        "model.add(Conv2D(64,(3,3),padding='same',input_shape=X_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=2,strides=2))\n",
        "# block 2\n",
        "model.add(Conv2D(128,(3,3),padding='same',input_shape=X_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=2,strides=2))\n",
        "# block 3\n",
        "model.add(Conv2D(256,(3,3),padding='same',input_shape=X_train.shape[1:]))\n",
        "model.add(Conv2D(256,(3,3),padding='same',input_shape=X_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=2,strides=2))\n",
        "# block 4\n",
        "model.add(Conv2D(512,(3,3),padding='same',input_shape=X_train.shape[1:]))\n",
        "model.add(Conv2D(512,(3,3),padding='same',input_shape=X_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=2,strides=2))\n",
        "# block 5\n",
        "model.add(Conv2D(512,(3,3),padding='same',input_shape=X_train.shape[1:]))\n",
        "model.add(Conv2D(512,(3,3),padding='same',input_shape=X_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(GlobalMaxPooling2D())\n",
        "# FL 4096x2 Fully conected layer\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "# FL 10\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.Adam(lr=0.0001)\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gqg-q8YBOuGi"
      },
      "outputs": [],
      "source": [
        "tbCallBack = keras.callbacks.TensorBoard(log_dir='./Graph2', histogram_freq=0, write_graph=True, write_images=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35mVIoMqOuGi",
        "outputId": "879d4168-5861-4cd5-c72d-c04499b57504"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-fafaa43913b4>:42: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(datagen.flow(X_train, y_train,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1562/1562 [==============================] - 49s 29ms/step - loss: 1.6843 - accuracy: 0.3585 - val_loss: 1.2790 - val_accuracy: 0.5254\n",
            "Epoch 2/50\n",
            "1562/1562 [==============================] - 43s 28ms/step - loss: 1.2404 - accuracy: 0.5493 - val_loss: 0.9976 - val_accuracy: 0.6343\n",
            "Epoch 3/50\n",
            "1562/1562 [==============================] - 44s 28ms/step - loss: 1.0317 - accuracy: 0.6317 - val_loss: 0.8689 - val_accuracy: 0.6942\n",
            "Epoch 4/50\n",
            "1562/1562 [==============================] - 44s 28ms/step - loss: 0.9120 - accuracy: 0.6794 - val_loss: 0.8214 - val_accuracy: 0.7170\n",
            "Epoch 5/50\n",
            "1562/1562 [==============================] - 44s 28ms/step - loss: 0.8290 - accuracy: 0.7117 - val_loss: 0.7852 - val_accuracy: 0.7318\n",
            "Epoch 6/50\n",
            "1562/1562 [==============================] - 43s 28ms/step - loss: 0.7713 - accuracy: 0.7316 - val_loss: 0.7208 - val_accuracy: 0.7504\n",
            "Epoch 7/50\n",
            "1562/1562 [==============================] - 45s 29ms/step - loss: 0.7175 - accuracy: 0.7502 - val_loss: 0.7024 - val_accuracy: 0.7591\n",
            "Epoch 8/50\n",
            "1562/1562 [==============================] - 44s 28ms/step - loss: 0.6806 - accuracy: 0.7656 - val_loss: 0.7049 - val_accuracy: 0.7608\n",
            "Epoch 9/50\n",
            "1562/1562 [==============================] - 43s 28ms/step - loss: 0.6478 - accuracy: 0.7751 - val_loss: 0.6642 - val_accuracy: 0.7754\n",
            "Epoch 10/50\n",
            "1562/1562 [==============================] - 44s 28ms/step - loss: 0.6114 - accuracy: 0.7890 - val_loss: 0.6699 - val_accuracy: 0.7770\n",
            "Epoch 11/50\n",
            "1562/1562 [==============================] - 45s 29ms/step - loss: 0.5910 - accuracy: 0.7972 - val_loss: 0.6736 - val_accuracy: 0.7779\n",
            "Epoch 12/50\n",
            "1562/1562 [==============================] - 45s 29ms/step - loss: 0.5646 - accuracy: 0.8038 - val_loss: 0.6299 - val_accuracy: 0.7894\n",
            "Epoch 13/50\n",
            "1562/1562 [==============================] - 45s 29ms/step - loss: 0.5416 - accuracy: 0.8107 - val_loss: 0.5829 - val_accuracy: 0.8049\n",
            "Epoch 14/50\n",
            "1562/1562 [==============================] - 43s 28ms/step - loss: 0.5274 - accuracy: 0.8182 - val_loss: 0.5744 - val_accuracy: 0.8071\n",
            "Epoch 15/50\n",
            "1562/1562 [==============================] - 44s 28ms/step - loss: 0.5087 - accuracy: 0.8253 - val_loss: 0.5882 - val_accuracy: 0.8044\n",
            "Epoch 16/50\n",
            "1562/1562 [==============================] - 44s 28ms/step - loss: 0.4953 - accuracy: 0.8289 - val_loss: 0.5521 - val_accuracy: 0.8206\n",
            "Epoch 17/50\n",
            "1562/1562 [==============================] - 44s 28ms/step - loss: 0.4830 - accuracy: 0.8331 - val_loss: 0.5350 - val_accuracy: 0.8239\n",
            "Epoch 18/50\n",
            "1562/1562 [==============================] - 45s 29ms/step - loss: 0.4652 - accuracy: 0.8401 - val_loss: 0.5994 - val_accuracy: 0.8065\n",
            "Epoch 19/50\n",
            "1562/1562 [==============================] - 43s 28ms/step - loss: 0.4558 - accuracy: 0.8428 - val_loss: 0.5749 - val_accuracy: 0.8159\n",
            "Epoch 20/50\n",
            "1562/1562 [==============================] - 44s 28ms/step - loss: 0.4388 - accuracy: 0.8470 - val_loss: 0.5497 - val_accuracy: 0.8213\n",
            "Epoch 21/50\n",
            "1562/1562 [==============================] - 44s 28ms/step - loss: 0.4250 - accuracy: 0.8532 - val_loss: 0.4915 - val_accuracy: 0.8367\n",
            "Epoch 22/50\n",
            "1562/1562 [==============================] - 45s 29ms/step - loss: 0.4186 - accuracy: 0.8555 - val_loss: 0.5652 - val_accuracy: 0.8173\n",
            "Epoch 23/50\n",
            "1562/1562 [==============================] - 45s 29ms/step - loss: 0.4122 - accuracy: 0.8575 - val_loss: 0.5282 - val_accuracy: 0.8282\n",
            "Epoch 24/50\n",
            "1562/1562 [==============================] - 43s 28ms/step - loss: 0.3998 - accuracy: 0.8614 - val_loss: 0.5215 - val_accuracy: 0.8290\n",
            "Epoch 25/50\n",
            "1562/1562 [==============================] - 46s 29ms/step - loss: 0.3896 - accuracy: 0.8646 - val_loss: 0.5209 - val_accuracy: 0.8346\n",
            "Epoch 26/50\n",
            "1562/1562 [==============================] - 44s 28ms/step - loss: 0.3797 - accuracy: 0.8679 - val_loss: 0.4850 - val_accuracy: 0.8419\n",
            "Epoch 27/50\n",
            "1562/1562 [==============================] - 44s 28ms/step - loss: 0.3760 - accuracy: 0.8689 - val_loss: 0.4634 - val_accuracy: 0.8437\n",
            "Epoch 28/50\n",
            "1562/1562 [==============================] - 44s 28ms/step - loss: 0.3666 - accuracy: 0.8720 - val_loss: 0.4606 - val_accuracy: 0.8528\n",
            "Epoch 29/50\n",
            "1562/1562 [==============================] - 44s 28ms/step - loss: 0.3599 - accuracy: 0.8737 - val_loss: 0.4944 - val_accuracy: 0.8421\n",
            "Epoch 30/50\n",
            "1562/1562 [==============================] - 44s 28ms/step - loss: 0.3526 - accuracy: 0.8773 - val_loss: 0.5039 - val_accuracy: 0.8421\n",
            "Epoch 31/50\n",
            "1562/1562 [==============================] - 44s 28ms/step - loss: 0.3461 - accuracy: 0.8788 - val_loss: 0.4897 - val_accuracy: 0.8414\n",
            "Epoch 32/50\n",
            "1562/1562 [==============================] - 44s 28ms/step - loss: 0.3433 - accuracy: 0.8797 - val_loss: 0.4614 - val_accuracy: 0.8498\n",
            "Epoch 33/50\n",
            "1562/1562 [==============================] - 44s 28ms/step - loss: 0.3335 - accuracy: 0.8859 - val_loss: 0.6020 - val_accuracy: 0.8332\n",
            "Epoch 34/50\n",
            "1562/1562 [==============================] - 44s 28ms/step - loss: 0.3296 - accuracy: 0.8863 - val_loss: 0.4933 - val_accuracy: 0.8494\n",
            "Epoch 35/50\n",
            "1562/1562 [==============================] - 45s 29ms/step - loss: 0.3167 - accuracy: 0.8891 - val_loss: 0.4522 - val_accuracy: 0.8571\n",
            "Epoch 36/50\n",
            "1562/1562 [==============================] - 44s 28ms/step - loss: 0.3150 - accuracy: 0.8912 - val_loss: 0.4549 - val_accuracy: 0.8570\n",
            "Epoch 37/50\n",
            "1562/1562 [==============================] - 44s 28ms/step - loss: 0.3089 - accuracy: 0.8930 - val_loss: 0.4975 - val_accuracy: 0.8530\n",
            "Epoch 38/50\n",
            "1562/1562 [==============================] - 43s 27ms/step - loss: 0.3062 - accuracy: 0.8924 - val_loss: 0.4630 - val_accuracy: 0.8589\n",
            "Epoch 39/50\n",
            "1562/1562 [==============================] - 44s 28ms/step - loss: 0.2996 - accuracy: 0.8960 - val_loss: 0.5240 - val_accuracy: 0.8470\n",
            "Epoch 40/50\n",
            "1562/1562 [==============================] - 45s 29ms/step - loss: 0.2899 - accuracy: 0.8986 - val_loss: 0.4724 - val_accuracy: 0.8618\n",
            "Epoch 41/50\n",
            "1562/1562 [==============================] - 44s 28ms/step - loss: 0.2904 - accuracy: 0.8996 - val_loss: 0.4709 - val_accuracy: 0.8563\n",
            "Epoch 42/50\n",
            "1562/1562 [==============================] - 43s 28ms/step - loss: 0.2824 - accuracy: 0.9012 - val_loss: 0.4859 - val_accuracy: 0.8542\n",
            "Epoch 43/50\n",
            "1562/1562 [==============================] - 45s 29ms/step - loss: 0.2758 - accuracy: 0.9031 - val_loss: 0.4751 - val_accuracy: 0.8585\n",
            "Epoch 44/50\n",
            "1562/1562 [==============================] - 44s 28ms/step - loss: 0.2780 - accuracy: 0.9028 - val_loss: 0.5007 - val_accuracy: 0.8489\n",
            "Epoch 45/50\n",
            "1562/1562 [==============================] - 43s 27ms/step - loss: 0.2670 - accuracy: 0.9081 - val_loss: 0.5128 - val_accuracy: 0.8513\n",
            "Epoch 46/50\n",
            "1562/1562 [==============================] - 44s 28ms/step - loss: 0.2695 - accuracy: 0.9054 - val_loss: 0.5617 - val_accuracy: 0.8381\n",
            "Epoch 47/50\n",
            "1562/1562 [==============================] - 45s 29ms/step - loss: 0.2691 - accuracy: 0.9057 - val_loss: 0.5033 - val_accuracy: 0.8471\n",
            "Epoch 48/50\n",
            "1562/1562 [==============================] - 43s 27ms/step - loss: 0.2582 - accuracy: 0.9114 - val_loss: 0.4797 - val_accuracy: 0.8567\n",
            "Epoch 49/50\n",
            "1562/1562 [==============================] - 44s 28ms/step - loss: 0.2571 - accuracy: 0.9113 - val_loss: 0.5069 - val_accuracy: 0.8610\n",
            "Epoch 50/50\n",
            "1562/1562 [==============================] - 43s 27ms/step - loss: 0.2542 - accuracy: 0.9120 - val_loss: 0.5051 - val_accuracy: 0.8482\n"
          ]
        }
      ],
      "source": [
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(X_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epoch,\n",
        "              validation_data=(X_test, y_test),\n",
        "              shuffle=True, callbacks=[tbCallBack])\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    '''\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "    '''\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(X_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model.fit_generator(datagen.flow(X_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        steps_per_epoch=X_train.shape[0] // batch_size,\n",
        "                        epochs=epoch,\n",
        "                        validation_data=(X_test, y_test), callbacks=[tbCallBack])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb"
      ],
      "metadata": {
        "id": "hEGcWnqLxwYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores=model.evaluate(X_test,y_test,verbose=1)\n",
        "print(\"Test Loss\",scores[0])\n",
        "print(\"Test Accuracy\",scores[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im0bJeudx6EX",
        "outputId": "bbceeb13-b21b-4230-b5c1-c07252cf1f94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 6ms/step - loss: 0.5051 - accuracy: 0.8482\n",
            "Test Loss 0.5051476359367371\n",
            "Test Accuracy 0.8482000231742859\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}